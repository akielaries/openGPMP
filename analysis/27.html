
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Cppcheck - HTML report - openGPMP</title>
    <link rel="stylesheet" href="style.css">
    <style>
pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: #ffffcc }
.highlight { background: #ffffff; }
.highlight .c { color: #888888 } /* Comment */
.highlight .err { color: #FF0000; background-color: #FFAAAA } /* Error */
.highlight .k { color: #008800; font-weight: bold } /* Keyword */
.highlight .o { color: #333333 } /* Operator */
.highlight .ch { color: #888888 } /* Comment.Hashbang */
.highlight .cm { color: #888888 } /* Comment.Multiline */
.highlight .cp { color: #557799 } /* Comment.Preproc */
.highlight .cpf { color: #888888 } /* Comment.PreprocFile */
.highlight .c1 { color: #888888 } /* Comment.Single */
.highlight .cs { color: #cc0000; font-weight: bold } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #c65d09; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008800; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008800; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008800; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #003388; font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: #008800; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #333399; font-weight: bold } /* Keyword.Type */
.highlight .m { color: #6600EE; font-weight: bold } /* Literal.Number */
.highlight .s { background-color: #fff0f0 } /* Literal.String */
.highlight .na { color: #0000CC } /* Name.Attribute */
.highlight .nb { color: #007020 } /* Name.Builtin */
.highlight .nc { color: #BB0066; font-weight: bold } /* Name.Class */
.highlight .no { color: #003366; font-weight: bold } /* Name.Constant */
.highlight .nd { color: #555555; font-weight: bold } /* Name.Decorator */
.highlight .ni { color: #880000; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #FF0000; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0066BB; font-weight: bold } /* Name.Function */
.highlight .nl { color: #997700; font-weight: bold } /* Name.Label */
.highlight .nn { color: #0e84b5; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #007700 } /* Name.Tag */
.highlight .nv { color: #996633 } /* Name.Variable */
.highlight .ow { color: #000000; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #6600EE; font-weight: bold } /* Literal.Number.Bin */
.highlight .mf { color: #6600EE; font-weight: bold } /* Literal.Number.Float */
.highlight .mh { color: #005588; font-weight: bold } /* Literal.Number.Hex */
.highlight .mi { color: #0000DD; font-weight: bold } /* Literal.Number.Integer */
.highlight .mo { color: #4400EE; font-weight: bold } /* Literal.Number.Oct */
.highlight .sa { background-color: #fff0f0 } /* Literal.String.Affix */
.highlight .sb { background-color: #fff0f0 } /* Literal.String.Backtick */
.highlight .sc { color: #0044DD } /* Literal.String.Char */
.highlight .dl { background-color: #fff0f0 } /* Literal.String.Delimiter */
.highlight .sd { color: #DD4422 } /* Literal.String.Doc */
.highlight .s2 { background-color: #fff0f0 } /* Literal.String.Double */
.highlight .se { color: #666666; font-weight: bold; background-color: #fff0f0 } /* Literal.String.Escape */
.highlight .sh { background-color: #fff0f0 } /* Literal.String.Heredoc */
.highlight .si { background-color: #eeeeee } /* Literal.String.Interpol */
.highlight .sx { color: #DD2200; background-color: #fff0f0 } /* Literal.String.Other */
.highlight .sr { color: #000000; background-color: #fff0ff } /* Literal.String.Regex */
.highlight .s1 { background-color: #fff0f0 } /* Literal.String.Single */
.highlight .ss { color: #AA6600 } /* Literal.String.Symbol */
.highlight .bp { color: #007020 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0066BB; font-weight: bold } /* Name.Function.Magic */
.highlight .vc { color: #336699 } /* Name.Variable.Class */
.highlight .vg { color: #dd7700; font-weight: bold } /* Name.Variable.Global */
.highlight .vi { color: #3333BB } /* Name.Variable.Instance */
.highlight .vm { color: #996633 } /* Name.Variable.Magic */
.highlight .il { color: #0000DD; font-weight: bold } /* Literal.Number.Integer.Long */
    </style>
    <script>
      function getStyle(el, styleProp) {
        var y;

        if (el.currentStyle) {
          y = el.currentStyle[styleProp];
        } else if (window.getComputedStyle) {
          y = document.defaultView.getComputedStyle(el, null).getPropertyValue(styleProp);
        }

        return y;
      }

      function toggle() {
        var el = this.expandable_content;
        var mark = this.expandable_marker;

        if (el.style.display === "block") {
          el.style.display = "none";
          mark.textContent = "[+]";
        } else {
          el.style.display = "block";
          mark.textContent = "[-]";
        }
      }

      function initExpandables() {
        var elements = document.querySelectorAll(".expandable");

        for (var i = 0, len = elements.length; i < len; i++) {
          var el = elements[i];
          var clickable = el.querySelector("span");
          var marker = clickable.querySelector(".marker");
          var content = el.querySelector(".content");
          var width = clickable.clientWidth - parseInt(getStyle(content, "padding-left")) - parseInt(getStyle(content, "padding-right"));
          content.style.width = width + "px";
          clickable.expandable_content = content;
          clickable.expandable_marker = marker;
          clickable.addEventListener("click", toggle);
        }
      }

      function toggleDisplay(cb) {
        var elements = document.querySelectorAll("." + cb.id);

        for (var i = 0, len = elements.length; i < len; i++) {
          elements[i].classList.toggle("id-filtered", !cb.checked);
        }

        updateFileRows();
      }

      function toggleSeverity(cb) {
        cb.parentElement.classList.toggle("unchecked", !cb.checked);
        var elements = document.querySelectorAll(".sev_" + cb.id);

        for (var i = 0, len = elements.length; i < len; i++) {
          elements[i].classList.toggle("severity-filtered", !cb.checked);
        }

        updateFileRows();
      }

      function toggleTool(cb) {
        cb.parentElement.classList.toggle("unchecked", !cb.checked);

        var elements;
        if (cb.id == "clang-tidy")
            elements = document.querySelectorAll("[class^=clang-tidy-]");
        else
            elements = document.querySelectorAll(".issue:not([class^=clang-tidy-])");

        for (var i = 0, len = elements.length; i < len; i++) {
          elements[i].classList.toggle("tool-filtered", !cb.checked);
        }

        updateFileRows();
      }

      function toggleAll() {
        var elements = document.querySelectorAll(".idToggle");

        // starting from 1 since 0 is the "toggle all" input
        for (var i = 1, len = elements.length; i < len; i++) {
          var changed = elements[i].checked != elements[0].checked;
          if (changed) {
            elements[i].checked = elements[0].checked;
            toggleDisplay(elements[i]);
          }
        }
      }

      function filterFile(filter) {
        var elements = document.querySelectorAll(".fileEntry");

        for (var i = 0, len = elements.length; i < len; i++) {
          var visible = elements[i].querySelector("tr").querySelector("td").textContent.toLowerCase().includes(filter.toLowerCase());
          elements[i].classList.toggle("text-filtered", !visible);
        }
      }

      function filterText(text) {
        filter = text.toLowerCase();
        var elements = document.querySelectorAll(".issue");

        for (var i = 0, len = elements.length; i < len; i++) {
          var visible = false;
          var fields = elements[i].querySelectorAll("td");
          for (var n = 0, num = fields.length; n < num; n++) {
            if (fields[n].textContent.toLowerCase().includes(filter)) {
              visible = true;
              break;
            }
          }
          elements[i].classList.toggle("text-filtered", !visible);
        }

        updateFileRows();
      }

      function updateFileRows(element) {
        var elements = document.querySelectorAll(".fileEntry");

        for (var i = 0, len = elements.length; i < len; i++) {
          var visible = elements[i].querySelector(".issue:not(.id-filtered):not(.severity-filtered):not(.tool-filtered):not(.text-filtered)");
          elements[i].classList.toggle("file-filtered", !visible);
        }
      }

      window.addEventListener("load", initExpandables);
    </script>
  </head>
  <body>
    <div id="wrapper">
    <div id="header" class="header">
      <h1>Cppcheck report - openGPMP: ../../include/ml/mlp_net.hpp</h1>

    </div>

    <div id="menu">
     <p><a href="index.html">Defects:</a> mlp_net.hpp</p>
<a href="27.html#line-248"> unreadVariable 248</a>
    </div>
    <div id="content">
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">  1</span>
<span class="normal">  2</span>
<span class="normal">  3</span>
<span class="normal">  4</span>
<span class="normal">  5</span>
<span class="normal">  6</span>
<span class="normal">  7</span>
<span class="normal">  8</span>
<span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><a id="line-1" name="line-1"></a><span class="cm">/*************************************************************************</span>
<a id="line-2" name="line-2"></a><span class="cm"> *</span>
<a id="line-3" name="line-3"></a><span class="cm"> *  Project</span>
<a id="line-4" name="line-4"></a><span class="cm"> *                         _____ _____  __  __ _____</span>
<a id="line-5" name="line-5"></a><span class="cm"> *                        / ____|  __ \|  \/  |  __ \</span>
<a id="line-6" name="line-6"></a><span class="cm"> *  ___  _ __   ___ _ __ | |  __| |__) | \  / | |__) |</span>
<a id="line-7" name="line-7"></a><span class="cm"> * / _ \| &#39;_ \ / _ \ &#39;_ \| | |_ |  ___/| |\/| |  ___/</span>
<a id="line-8" name="line-8"></a><span class="cm"> *| (_) | |_) |  __/ | | | |__| | |    | |  | | |</span>
<a id="line-9" name="line-9"></a><span class="cm"> * \___/| .__/ \___|_| |_|\_____|_|    |_|  |_|_|</span>
<a id="line-10" name="line-10"></a><span class="cm"> *      | |</span>
<a id="line-11" name="line-11"></a><span class="cm"> *      |_|</span>
<a id="line-12" name="line-12"></a><span class="cm"> *</span>
<a id="line-13" name="line-13"></a><span class="cm"> * Copyright (C) Akiel Aries, &lt;akiel@akiel.org&gt;, et al.</span>
<a id="line-14" name="line-14"></a><span class="cm"> *</span>
<a id="line-15" name="line-15"></a><span class="cm"> * This software is licensed as described in the file LICENSE, which</span>
<a id="line-16" name="line-16"></a><span class="cm"> * you should have received as part of this distribution. The terms</span>
<a id="line-17" name="line-17"></a><span class="cm"> * among other details are referenced in the official documentation</span>
<a id="line-18" name="line-18"></a><span class="cm"> * seen here : https://akielaries.github.io/openGPMP/ along with</span>
<a id="line-19" name="line-19"></a><span class="cm"> * important files seen in this project.</span>
<a id="line-20" name="line-20"></a><span class="cm"> *</span>
<a id="line-21" name="line-21"></a><span class="cm"> * You may opt to use, copy, modify, merge, publish, distribute</span>
<a id="line-22" name="line-22"></a><span class="cm"> * and/or sell copies of the Software, and permit persons to whom</span>
<a id="line-23" name="line-23"></a><span class="cm"> * the Software is furnished to do so, under the terms of the</span>
<a id="line-24" name="line-24"></a><span class="cm"> * LICENSE file. As this is an Open Source effort, all implementations</span>
<a id="line-25" name="line-25"></a><span class="cm"> * must be of the same methodology.</span>
<a id="line-26" name="line-26"></a><span class="cm"> *</span>
<a id="line-27" name="line-27"></a><span class="cm"> *</span>
<a id="line-28" name="line-28"></a><span class="cm"> *</span>
<a id="line-29" name="line-29"></a><span class="cm"> * This software is distributed on an AS IS basis, WITHOUT</span>
<a id="line-30" name="line-30"></a><span class="cm"> * WARRANTY OF ANY KIND, either express or implied.</span>
<a id="line-31" name="line-31"></a><span class="cm"> *</span>
<a id="line-32" name="line-32"></a><span class="cm"> ************************************************************************/</span><span class="w"></span>
<a id="line-33" name="line-33"></a>
<a id="line-34" name="line-34"></a><span class="cm">/**</span>
<a id="line-35" name="line-35"></a><span class="cm"> * @file</span>
<a id="line-36" name="line-36"></a><span class="cm"> *</span>
<a id="line-37" name="line-37"></a><span class="cm"> * Multi-Layer Perceptron Neural Networks containing a</span>
<a id="line-38" name="line-38"></a><span class="cm"> * Primary and Secondary network</span>
<a id="line-39" name="line-39"></a><span class="cm"> */</span><span class="w"></span>
<a id="line-40" name="line-40"></a><span class="cp">#ifndef MLP_NETWORK_HPP</span>
<a id="line-41" name="line-41"></a><span class="cp">#define MLP_NETWORK_HPP</span>
<a id="line-42" name="line-42"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;../linalg.hpp&quot;</span><span class="cp"></span>
<a id="line-43" name="line-43"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;../linalg/mtx_tmpl.hpp&quot;</span><span class="cp"></span>
<a id="line-44" name="line-44"></a>
<a id="line-45" name="line-45"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cassert&gt;</span><span class="cp"></span>
<a id="line-46" name="line-46"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;fstream&gt;</span><span class="cp"></span>
<a id="line-47" name="line-47"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;random&gt;</span><span class="cp"></span>
<a id="line-48" name="line-48"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>
<a id="line-49" name="line-49"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;utility&gt;</span><span class="cp"></span>
<a id="line-50" name="line-50"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span><span class="cp"></span>
<a id="line-51" name="line-51"></a>
<a id="line-52" name="line-52"></a><span class="k">namespace</span><span class="w"> </span><span class="nn">gpmp</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-53" name="line-53"></a>
<a id="line-54" name="line-54"></a><span class="cm">/**</span>
<a id="line-55" name="line-55"></a><span class="cm"> * @brief Namespace for openGPMP Machine Learning</span>
<a id="line-56" name="line-56"></a><span class="cm"> */</span><span class="w"></span>
<a id="line-57" name="line-57"></a><span class="k">namespace</span><span class="w"> </span><span class="nn">ml</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-58" name="line-58"></a>
<a id="line-59" name="line-59"></a><span class="cm">/*</span>
<a id="line-60" name="line-60"></a><span class="cm"> * TODO</span>
<a id="line-61" name="line-61"></a><span class="cm"> * Think of using extended or derived classes</span>
<a id="line-62" name="line-62"></a><span class="cm"> *</span>
<a id="line-63" name="line-63"></a><span class="cm"> * Weights : MLP</span>
<a id="line-64" name="line-64"></a><span class="cm"> *</span>
<a id="line-65" name="line-65"></a><span class="cm"> */</span><span class="w"></span>
<a id="line-66" name="line-66"></a><span class="k">struct</span><span class="w"> </span><span class="nc">neuron</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-67" name="line-67"></a><span class="w">    </span><span class="c1">// exit</span>
<a id="line-68" name="line-68"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">sortir</span><span class="p">;</span><span class="w"></span>
<a id="line-69" name="line-69"></a><span class="w">    </span><span class="c1">// error</span>
<a id="line-70" name="line-70"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">err</span><span class="p">;</span><span class="w"></span>
<a id="line-71" name="line-71"></a><span class="w">    </span><span class="c1">// weight</span>
<a id="line-72" name="line-72"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">wt</span><span class="p">;</span><span class="w"></span>
<a id="line-73" name="line-73"></a><span class="w">    </span><span class="c1">// last weight</span>
<a id="line-74" name="line-74"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">wt_last</span><span class="p">;</span><span class="w"></span>
<a id="line-75" name="line-75"></a><span class="w">    </span><span class="c1">// saved weight</span>
<a id="line-76" name="line-76"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">wt_saved</span><span class="p">;</span><span class="w"></span>
<a id="line-77" name="line-77"></a><span class="p">};</span><span class="w"></span>
<a id="line-78" name="line-78"></a>
<a id="line-79" name="line-79"></a><span class="k">struct</span><span class="w"> </span><span class="nc">layer</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-80" name="line-80"></a><span class="w">    </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">num_neurons</span><span class="p">;</span><span class="w"></span>
<a id="line-81" name="line-81"></a><span class="w">    </span><span class="n">neuron</span><span class="w"> </span><span class="o">*</span><span class="n">neuron_ptr</span><span class="p">;</span><span class="w"></span>
<a id="line-82" name="line-82"></a><span class="p">};</span><span class="w"></span>
<a id="line-83" name="line-83"></a>
<a id="line-84" name="line-84"></a><span class="cm">/**</span>
<a id="line-85" name="line-85"></a><span class="cm"> * @brief Primary Multi-Layer Perceptron Class</span>
<a id="line-86" name="line-86"></a><span class="cm"> */</span><span class="w"></span>
<a id="line-87" name="line-87"></a><span class="k">class</span><span class="w"> </span><span class="nc">PrimaryMLP</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-88" name="line-88"></a><span class="w">    </span><span class="cm">/* initialize random values for the network */</span><span class="w"></span>
<a id="line-89" name="line-89"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">rand_init</span><span class="p">();</span><span class="w"></span>
<a id="line-90" name="line-90"></a><span class="w">    </span><span class="cm">/* check that random is an integer */</span><span class="w"></span>
<a id="line-91" name="line-91"></a><span class="w">    </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">rand_int</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">low</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">hi</span><span class="p">);</span><span class="w"></span>
<a id="line-92" name="line-92"></a><span class="w">    </span><span class="cm">/*check random is a real number */</span><span class="w"></span>
<a id="line-93" name="line-93"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="nf">rand_real</span><span class="p">(</span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">low</span><span class="p">,</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">hi</span><span class="p">);</span><span class="w"></span>
<a id="line-94" name="line-94"></a><span class="w">    </span><span class="cm">/*return the number of layers in the network */</span><span class="w"></span>
<a id="line-95" name="line-95"></a><span class="w">    </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">num_layers</span><span class="p">;</span><span class="w"></span>
<a id="line-96" name="line-96"></a><span class="w">    </span><span class="n">layer</span><span class="w"> </span><span class="o">*</span><span class="n">layer_ptr</span><span class="p">;</span><span class="w"></span>
<a id="line-97" name="line-97"></a><span class="w">    </span><span class="cm">/**</span>
<a id="line-98" name="line-98"></a><span class="cm">     * @brief Mean Squared Error</span>
<a id="line-99" name="line-99"></a><span class="cm">     */</span><span class="w"></span>
<a id="line-100" name="line-100"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">_MSE</span><span class="p">;</span><span class="w"></span>
<a id="line-101" name="line-101"></a><span class="w">    </span><span class="cm">/**</span>
<a id="line-102" name="line-102"></a><span class="cm">     * @brief Mean Absolute Error</span>
<a id="line-103" name="line-103"></a><span class="cm">     */</span><span class="w"></span>
<a id="line-104" name="line-104"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">_MAE</span><span class="p">;</span><span class="w"></span>
<a id="line-105" name="line-105"></a>
<a id="line-106" name="line-106"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">set_signal_in</span><span class="p">(</span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">input</span><span class="p">);</span><span class="w"></span>
<a id="line-107" name="line-107"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">get_signal_out</span><span class="p">(</span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="p">);</span><span class="w"></span>
<a id="line-108" name="line-108"></a>
<a id="line-109" name="line-109"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">weights_save</span><span class="p">();</span><span class="w"></span>
<a id="line-110" name="line-110"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">weights_rand</span><span class="p">();</span><span class="w"></span>
<a id="line-111" name="line-111"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">weights_restore</span><span class="p">();</span><span class="w"></span>
<a id="line-112" name="line-112"></a><span class="w">    </span><span class="cm">/*adjust weights */</span><span class="w"></span>
<a id="line-113" name="line-113"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">weights_adjust</span><span class="p">();</span><span class="w"></span>
<a id="line-114" name="line-114"></a>
<a id="line-115" name="line-115"></a><span class="w">    </span><span class="cm">/* propogate given the signal */</span><span class="w"></span>
<a id="line-116" name="line-116"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">prop_signal</span><span class="p">();</span><span class="w"></span>
<a id="line-117" name="line-117"></a><span class="w">    </span><span class="cm">/* returns the computed output error */</span><span class="w"></span>
<a id="line-118" name="line-118"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">output_err</span><span class="p">(</span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">target</span><span class="p">);</span><span class="w"></span>
<a id="line-119" name="line-119"></a><span class="w">    </span><span class="cm">/* returns the computed error from backwards propogation */</span><span class="w"></span>
<a id="line-120" name="line-120"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">back_prop_err</span><span class="p">();</span><span class="w"></span>
<a id="line-121" name="line-121"></a><span class="w">    </span><span class="cm">/* simulate the Multi-Layer Perceptron Neual Network */</span><span class="w"></span>
<a id="line-122" name="line-122"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">simulate</span><span class="p">(</span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">input</span><span class="p">,</span><span class="w"></span>
<a id="line-123" name="line-123"></a><span class="w">                  </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">output</span><span class="p">,</span><span class="w"></span>
<a id="line-124" name="line-124"></a><span class="w">                  </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="o">*</span><span class="n">target</span><span class="p">,</span><span class="w"></span>
<a id="line-125" name="line-125"></a><span class="w">                  </span><span class="kt">bool</span><span class="w"> </span><span class="n">training</span><span class="p">);</span><span class="w"></span>
<a id="line-126" name="line-126"></a>
<a id="line-127" name="line-127"></a><span class="w">  </span><span class="k">public</span><span class="o">:</span><span class="w"></span>
<a id="line-128" name="line-128"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">_Eta</span><span class="p">;</span><span class="w"></span>
<a id="line-129" name="line-129"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">_Alpha</span><span class="p">;</span><span class="w"></span>
<a id="line-130" name="line-130"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">_Gain</span><span class="p">;</span><span class="w"></span>
<a id="line-131" name="line-131"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">_AvgTestError</span><span class="p">;</span><span class="w"></span>
<a id="line-132" name="line-132"></a>
<a id="line-133" name="line-133"></a><span class="w">    </span><span class="cm">/* CONSTRUCT */</span><span class="w"></span>
<a id="line-134" name="line-134"></a><span class="w">    </span><span class="n">PrimaryMLP</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">nl</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">npl</span><span class="p">[]);</span><span class="w"></span>
<a id="line-135" name="line-135"></a><span class="w">    </span><span class="cm">/* DECONSTRUCT */</span><span class="w"></span>
<a id="line-136" name="line-136"></a><span class="w">    </span><span class="o">~</span><span class="n">PrimaryMLP</span><span class="p">();</span><span class="w"></span>
<a id="line-137" name="line-137"></a>
<a id="line-138" name="line-138"></a><span class="w">    </span><span class="cm">/* method to train the network given data*/</span><span class="w"></span>
<a id="line-139" name="line-139"></a><span class="w">    </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">fnames</span><span class="p">);</span><span class="w"></span>
<a id="line-140" name="line-140"></a><span class="w">    </span><span class="cm">/* method to test given data*/</span><span class="w"></span>
<a id="line-141" name="line-141"></a><span class="w">    </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">test</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">fname</span><span class="p">);</span><span class="w"></span>
<a id="line-142" name="line-142"></a><span class="w">    </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">();</span><span class="w"></span>
<a id="line-143" name="line-143"></a>
<a id="line-144" name="line-144"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">fname</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="o">&amp;</span><span class="n">max_iters</span><span class="p">);</span><span class="w"></span>
<a id="line-145" name="line-145"></a><span class="p">};</span><span class="w"></span>
<a id="line-146" name="line-146"></a>
<a id="line-147" name="line-147"></a><span class="cm">/**</span>
<a id="line-148" name="line-148"></a><span class="cm"> * @brief Secondary Multi-Layer Perceptron Class making use of</span>
<a id="line-149" name="line-149"></a><span class="cm"> * the Linear Algebra module</span>
<a id="line-150" name="line-150"></a><span class="cm"> */</span><span class="w"></span>
<a id="line-151" name="line-151"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">SecondaryMLP</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-152" name="line-152"></a><span class="w">  </span><span class="k">public</span><span class="o">:</span><span class="w"></span>
<a id="line-153" name="line-153"></a><span class="w">    </span><span class="cm">/**</span>
<a id="line-154" name="line-154"></a><span class="cm">     * @details Logging function for collecting the results</span>
<a id="line-155" name="line-155"></a><span class="cm">     */</span><span class="w"></span>
<a id="line-156" name="line-156"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="n">log</span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">file</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">y_hat</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-157" name="line-157"></a><span class="w">        </span><span class="c1">// mean squared error</span>
<a id="line-158" name="line-158"></a><span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">mse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y_hat</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span><span class="w"></span>
<a id="line-159" name="line-159"></a><span class="w">        </span><span class="n">mse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mse</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">mse</span><span class="p">;</span><span class="w"></span>
<a id="line-160" name="line-160"></a><span class="w">        </span><span class="n">file</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">mse</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">y</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="w"></span>
<a id="line-161" name="line-161"></a><span class="w">             </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">y_hat</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">;</span><span class="w"></span>
<a id="line-162" name="line-162"></a><span class="w">    </span><span class="p">}</span><span class="w"></span>
<a id="line-163" name="line-163"></a>
<a id="line-164" name="line-164"></a><span class="w">    </span><span class="cm">/**</span>
<a id="line-165" name="line-165"></a><span class="cm">     * @brief Sigmoid activation function</span>
<a id="line-166" name="line-166"></a><span class="cm">     *</span>
<a id="line-167" name="line-167"></a><span class="cm">     * @param[in] x : (float)</span>
<a id="line-168" name="line-168"></a><span class="cm">     */</span><span class="w"></span>
<a id="line-169" name="line-169"></a><span class="w">    </span><span class="kr">inline</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">sigmoid_activ</span><span class="p">(</span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-170" name="line-170"></a><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="mf">1.0f</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">));</span><span class="w"></span>
<a id="line-171" name="line-171"></a><span class="w">    </span><span class="p">}</span><span class="w"></span>
<a id="line-172" name="line-172"></a>
<a id="line-173" name="line-173"></a><span class="w">    </span><span class="cm">/**</span>
<a id="line-174" name="line-174"></a><span class="cm">     * @brief Sigmoid Derivative for backwards propogation</span>
<a id="line-175" name="line-175"></a><span class="cm">     *</span>
<a id="line-176" name="line-176"></a><span class="cm">     * @param[in] x : (float)</span>
<a id="line-177" name="line-177"></a><span class="cm">     */</span><span class="w"></span>
<a id="line-178" name="line-178"></a><span class="w">    </span><span class="kr">inline</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">sigmoid_deriv</span><span class="p">(</span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-179" name="line-179"></a><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x</span><span class="p">));</span><span class="w"></span>
<a id="line-180" name="line-180"></a><span class="w">    </span><span class="p">}</span><span class="w"></span>
<a id="line-181" name="line-181"></a>
<a id="line-182" name="line-182"></a><span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layer_units</span><span class="p">;</span><span class="w"></span>
<a id="line-183" name="line-183"></a><span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">gpmp</span><span class="o">::</span><span class="n">linalg</span><span class="o">::</span><span class="n">Matrix</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">bias_vectors</span><span class="p">;</span><span class="w"></span>
<a id="line-184" name="line-184"></a><span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">gpmp</span><span class="o">::</span><span class="n">linalg</span><span class="o">::</span><span class="n">Matrix</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">wt_mtx</span><span class="p">;</span><span class="w"></span>
<a id="line-185" name="line-185"></a><span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">gpmp</span><span class="o">::</span><span class="n">linalg</span><span class="o">::</span><span class="n">Matrix</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">activations</span><span class="p">;</span><span class="w"></span>
<a id="line-186" name="line-186"></a>
<a id="line-187" name="line-187"></a><span class="w">    </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">lr</span><span class="p">;</span><span class="w"></span>
<a id="line-188" name="line-188"></a>
<a id="line-189" name="line-189"></a><span class="w">    </span><span class="cm">/**</span>
<a id="line-190" name="line-190"></a><span class="cm">     * @details Secondary Multi-Layer Perceptron Constructor</span>
<a id="line-191" name="line-191"></a><span class="cm">     * Initialize a set of weights + biases for each layer</span>
<a id="line-192" name="line-192"></a><span class="cm">     * set to random Gaussian Noise related values</span>
<a id="line-193" name="line-193"></a><span class="cm">     */</span><span class="w"></span>
<a id="line-194" name="line-194"></a><span class="w">    </span><span class="k">explicit</span><span class="w"> </span><span class="n">SecondaryMLP</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layer_units</span><span class="p">,</span><span class="w"></span>
<a id="line-195" name="line-195"></a><span class="w">                          </span><span class="kt">long</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">lr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">.001</span><span class="p">)</span><span class="w"></span>
<a id="line-196" name="line-196"></a><span class="w">        </span><span class="o">:</span><span class="w"> </span><span class="n">layer_units</span><span class="p">(</span><span class="n">layer_units</span><span class="p">),</span><span class="w"> </span><span class="n">wt_mtx</span><span class="p">(),</span><span class="w"> </span><span class="n">bias_vectors</span><span class="p">(),</span><span class="w"> </span><span class="n">lr</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-197" name="line-197"></a><span class="w">        </span><span class="c1">// traverse the elements</span>
<a id="line-198" name="line-198"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">layer_units</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-199" name="line-199"></a><span class="w">            </span><span class="c1">// size of inputs</span>
<a id="line-200" name="line-200"></a><span class="w">            </span><span class="kt">size_t</span><span class="w"> </span><span class="n">inputs</span><span class="p">{</span><span class="n">layer_units</span><span class="p">[</span><span class="n">i</span><span class="p">]};</span><span class="w"></span>
<a id="line-201" name="line-201"></a><span class="w">            </span><span class="c1">// size of outputs</span>
<a id="line-202" name="line-202"></a><span class="w">            </span><span class="kt">size_t</span><span class="w"> </span><span class="n">outputs</span><span class="p">{</span><span class="n">layer_units</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">]};</span><span class="w"></span>
<a id="line-203" name="line-203"></a>
<a id="line-204" name="line-204"></a><span class="w">            </span><span class="c1">// set to random Guassian Noise related values</span>
<a id="line-205" name="line-205"></a><span class="w">            </span><span class="c1">// weights</span>
<a id="line-206" name="line-206"></a><span class="w">            </span><span class="k">auto</span><span class="w"> </span><span class="n">gauss_wt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gpmp</span><span class="o">::</span><span class="n">linalg</span><span class="o">::</span><span class="n">mtx</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">randn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">);</span><span class="w"></span>
<a id="line-207" name="line-207"></a><span class="w">            </span><span class="n">wt_mtx</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">gauss_wt</span><span class="p">);</span><span class="w"></span>
<a id="line-208" name="line-208"></a><span class="w">            </span><span class="c1">// biases</span>
<a id="line-209" name="line-209"></a><span class="w">            </span><span class="k">auto</span><span class="w"> </span><span class="n">bias_wt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gpmp</span><span class="o">::</span><span class="n">linalg</span><span class="o">::</span><span class="n">mtx</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">randn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<a id="line-210" name="line-210"></a><span class="w">            </span><span class="n">bias_vectors</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">bias_wt</span><span class="p">);</span><span class="w"></span>
<a id="line-211" name="line-211"></a><span class="w">            </span><span class="c1">// activation function</span>
<a id="line-212" name="line-212"></a><span class="w">            </span><span class="n">activations</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">layer_units</span><span class="p">.</span><span class="n">size</span><span class="p">());</span><span class="w"></span>
<a id="line-213" name="line-213"></a><span class="w">        </span><span class="p">}</span><span class="w"></span>
<a id="line-214" name="line-214"></a><span class="w">    </span><span class="p">}</span><span class="w"></span>
<a id="line-215" name="line-215"></a><span class="w">    </span><span class="cm">/**</span>
<a id="line-216" name="line-216"></a><span class="cm">     * @details Forward passes compute the activations at a specific</span>
<a id="line-217" name="line-217"></a><span class="cm">     * layer. This method saves the results to the activations Matrix</span>
<a id="line-218" name="line-218"></a><span class="cm">     * passing it forwards to use as an input paramater on the next</span>
<a id="line-219" name="line-219"></a><span class="cm">     * layer</span>
<a id="line-220" name="line-220"></a><span class="cm">     */</span><span class="w"></span>
<a id="line-221" name="line-221"></a><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">prop_forwards</span><span class="p">(</span><span class="n">gpmp</span><span class="o">::</span><span class="n">linalg</span><span class="o">::</span><span class="n">Matrix</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-222" name="line-222"></a><span class="w">        </span><span class="n">assert</span><span class="p">(</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">layer_units</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">get</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">));</span><span class="w"></span>
<a id="line-223" name="line-223"></a><span class="w">        </span><span class="c1">// input = to previously declared acitvations method</span>
<a id="line-224" name="line-224"></a><span class="w">        </span><span class="n">activations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">;</span><span class="w"></span>
<a id="line-225" name="line-225"></a><span class="w">        </span><span class="n">gpmp</span><span class="o">::</span><span class="n">linalg</span><span class="o">::</span><span class="n">Matrix</span><span class="w"> </span><span class="nf">prev</span><span class="p">(</span><span class="n">x</span><span class="p">);</span><span class="w"></span>
<a id="line-226" name="line-226"></a>
<a id="line-227" name="line-227"></a><span class="w">        </span><span class="c1">// traverse layer units</span>
<a id="line-228" name="line-228"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">layer_units</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-229" name="line-229"></a><span class="w">            </span><span class="n">gpmp</span><span class="o">::</span><span class="n">linalg</span><span class="o">::</span><span class="n">Matrix</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wt_mtx</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">mult</span><span class="p">(</span><span class="n">prev</span><span class="p">);</span><span class="w"></span>
<a id="line-230" name="line-230"></a><span class="w">            </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">bias_vectors</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>
<a id="line-231" name="line-231"></a><span class="w">            </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">.</span><span class="n">apply_function</span><span class="p">(</span><span class="o">&amp;</span><span class="n">SecondaryMLP</span><span class="o">::</span><span class="n">sigmoid_activ</span><span class="p">);</span><span class="w"></span>
<a id="line-232" name="line-232"></a><span class="w">            </span><span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">;</span><span class="w"></span>
<a id="line-233" name="line-233"></a><span class="w">            </span><span class="n">prev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">;</span><span class="w"></span>
<a id="line-234" name="line-234"></a><span class="w">        </span><span class="p">}</span><span class="w"></span>
<a id="line-235" name="line-235"></a><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">prev</span><span class="p">;</span><span class="w"></span>
<a id="line-236" name="line-236"></a><span class="w">    </span><span class="p">}</span><span class="w"></span>
<a id="line-237" name="line-237"></a><span class="w">    </span><span class="cm">/**</span>
<a id="line-238" name="line-238"></a><span class="cm">     * @details Backwards Propagation is utilized to optimize the</span>
<a id="line-239" name="line-239"></a><span class="cm">     * net&#39;s weights. Enabling learning how to correctly map arbitrary</span>
<a id="line-240" name="line-240"></a><span class="cm">     * inputs to outputs. The goal being to update each weight of the</span>
<a id="line-241" name="line-241"></a><span class="cm">     * network allowing them to increase the chance of the actual</span>
<a id="line-242" name="line-242"></a><span class="cm">     * output being closer to the target output.</span>
<a id="line-243" name="line-243"></a><span class="cm">     * This method takes the target output as an input parameter</span>
<a id="line-244" name="line-244"></a><span class="cm">     */</span><span class="w"></span>
<a id="line-245" name="line-245"></a><span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="n">prop_backwards</span><span class="p">(</span><span class="n">gpmp</span><span class="o">::</span><span class="n">linalg</span><span class="o">::</span><span class="n">Matrix</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="w"> </span><span class="n">target</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-246" name="line-246"></a><span class="w">        </span><span class="n">assert</span><span class="p">(</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="o">&gt;</span><span class="p">(</span><span class="n">target</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">layer_units</span><span class="p">.</span><span class="n">back</span><span class="p">());</span><span class="w"></span>
<a id="line-247" name="line-247"></a><span class="w">        </span><span class="c1">// calculate the error, target - ouput</span>
<a id="line-248" name="line-248"></a><span class="hll"><span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">target</span><span class="p">;</span><span class="w"></span><span class="error2">&lt;--- Variable 'y' is assigned a value that is never used.</span>
</span><a id="line-249" name="line-249"></a><span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">y_hat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">activations</span><span class="p">.</span><span class="n">back</span><span class="p">();</span><span class="w"></span>
<a id="line-250" name="line-250"></a><span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y_hat</span><span class="p">;</span><span class="w"></span>
<a id="line-251" name="line-251"></a><span class="w">        </span><span class="c1">// back propagate the error calculated from output to input</span>
<a id="line-252" name="line-252"></a><span class="w">        </span><span class="c1">// and step the weights</span>
<a id="line-253" name="line-253"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wt_mtx</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="o">--</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<a id="line-254" name="line-254"></a><span class="w">            </span><span class="c1">// calculate errors for previous layer</span>
<a id="line-255" name="line-255"></a><span class="w">            </span><span class="k">auto</span><span class="w"> </span><span class="n">wt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wt_mtx</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">T</span><span class="p">();</span><span class="w"></span>
<a id="line-256" name="line-256"></a><span class="w">            </span><span class="k">auto</span><span class="w"> </span><span class="n">prior_errs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wt</span><span class="p">.</span><span class="n">mult</span><span class="p">(</span><span class="n">err</span><span class="p">);</span><span class="w"></span>
<a id="line-257" name="line-257"></a><span class="w">            </span><span class="k">auto</span><span class="w"> </span><span class="n">outputs_d</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<a id="line-258" name="line-258"></a><span class="w">                </span><span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">].</span><span class="n">apply_function</span><span class="p">(</span><span class="o">&amp;</span><span class="n">SecondaryMLP</span><span class="o">::</span><span class="n">sigmoid_deriv</span><span class="p">);</span><span class="w"></span>
<a id="line-259" name="line-259"></a><span class="w">            </span><span class="k">auto</span><span class="w"> </span><span class="n">gradients</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">err</span><span class="p">.</span><span class="n">hadamard</span><span class="p">(</span><span class="n">outputs_d</span><span class="p">);</span><span class="w"></span>
<a id="line-260" name="line-260"></a><span class="w">            </span><span class="n">gradients</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gradients</span><span class="p">.</span><span class="n">scalar_mult</span><span class="p">(</span><span class="n">lr</span><span class="p">);</span><span class="w"></span>
<a id="line-261" name="line-261"></a><span class="w">            </span><span class="k">auto</span><span class="w"> </span><span class="n">trans_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">T</span><span class="p">();</span><span class="w"></span>
<a id="line-262" name="line-262"></a><span class="w">            </span><span class="k">auto</span><span class="w"> </span><span class="n">gradients_wt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gradients</span><span class="p">.</span><span class="n">mult</span><span class="p">(</span><span class="n">trans_a</span><span class="p">);</span><span class="w"></span>
<a id="line-263" name="line-263"></a>
<a id="line-264" name="line-264"></a><span class="w">            </span><span class="c1">// adjust the networks weights based on propagation</span>
<a id="line-265" name="line-265"></a><span class="w">            </span><span class="c1">// technique</span>
<a id="line-266" name="line-266"></a><span class="w">            </span><span class="n">bias_vectors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bias_vectors</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">add</span><span class="p">(</span><span class="n">gradients</span><span class="p">);</span><span class="w"></span>
<a id="line-267" name="line-267"></a><span class="w">            </span><span class="n">wt_mtx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wt_mtx</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">add</span><span class="p">(</span><span class="n">gradients_wt</span><span class="p">);</span><span class="w"></span>
<a id="line-268" name="line-268"></a><span class="w">            </span><span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prior_errs</span><span class="p">;</span><span class="w"></span>
<a id="line-269" name="line-269"></a><span class="w">        </span><span class="p">}</span><span class="w"></span>
<a id="line-270" name="line-270"></a><span class="w">    </span><span class="p">}</span><span class="w"></span>
<a id="line-271" name="line-271"></a><span class="p">};</span><span class="w"></span>
<a id="line-272" name="line-272"></a>
<a id="line-273" name="line-273"></a><span class="p">}</span><span class="w"> </span><span class="c1">// namespace ml</span>
<a id="line-274" name="line-274"></a>
<a id="line-275" name="line-275"></a><span class="p">}</span><span class="w"> </span><span class="c1">// namespace gpmp</span>
<a id="line-276" name="line-276"></a>
<a id="line-277" name="line-277"></a><span class="cp">#endif</span>
</pre></div>
</td></tr></table>
    </div>
    <div id="footer" class="footer">
      <p>
        Created by Cppcheck 2.7 (<a href="https://cppcheck.sourceforge.io">Sourceforge</a>, <a href="irc://irc.freenode.net/cppcheck">IRC</a>)
      </p>
    </div>
    </div>
  </body>
</html>
